---
sidebar: upgrade-arl-auto-app_sidebar 
permalink: upgrade-arl-auto-app/setting_the_fc_or_uta_uta2_configuration_on_node3.html 
keywords: setting, fc, uta, uta2 configuration, node 
summary: 如果 node3 具有板载 FC 端口，板载统一目标适配器（ UTA/UTA2 ）端口或 UTA/UTA2 卡。 
---
= 在 node3 上设置 FC 或 UTA/UTA2 配置
:hardbreaks:
:nofooter: 
:icons: font
:linkattrs: 
:imagesdir: ./media/


[role="lead"]
如果 node3 具有板载 FC 端口，板载统一目标适配器（ UTA/UTA2 ）端口或 UTA/UTA2 卡，则必须先配置这些设置，然后才能完成其余操作步骤。

您可能需要完成此部分 link:setting_the_fc_or_uta_uta2_configuration_on_node3.html#configuring-fc-ports-on-node3["在 node3 上配置 FC 端口"]，部分 或这两个部分。


NOTE: NetApp 营销材料可能会使用术语 UTA2 来指代 CNA 适配器和端口。但是，命令行界面使用术语 CNA 。

* 如果 node3 没有板载 FC 端口，板载 UTA/UTA2 端口或 UTA/UTA2 卡，并且您要升级具有存储磁盘的系统，则可以跳至 link:verifying_the_node3_installation.html["验证节点 3 安装"] 部分。
* 但是，如果您使用的是 V 系列系统或安装了 FlexArray 虚拟化软件和存储阵列的系统，并且 node3 没有板载 FC 端口，板载 UTA/UTA 端口或 UTA/UTA2 卡，请返回到部分 link:installing_and_booting_node3.html["安装并启动 node3"] 并恢复步骤 23 中的部分。


.选项
* link:setting_the_fc_or_uta_uta2_configuration_on_node3.html#configure-fc-ports-on-node3["在 node3 上配置 FC 端口"]
* link:setting_the_fc_or_uta_uta2_configuration_on_node3.html#check-and-configure-utauta2-ports-on-node3["检查并配置 node3 上的 UTA/UTA2 端口"]




== 在 node3 上配置 FC 端口

如果 node3 具有板载或 FC 适配器上的 FC 端口，则必须先在节点上设置端口配置，然后再将其投入使用，因为这些端口未经过预配置。如果未配置端口，则可能会发生服务中断。

您必须具有在部分中保存的 node1 中的 FC 端口设置值 link:preparing_the_nodes_for_upgrade.html["准备要升级的节点"]。

如果您的系统没有 FC 配置，则可以跳过此部分。如果您的系统具有板载 UTA/UTA2 端口或 UTA/UTA2 卡，则可以在中对其进行配置 link:setting_the_fc_or_uta_uta2_configuration_on_node3.html#check-and-configure-utauta2-ports-on-node3["检查并配置 node3 上的 UTA/UTA2 端口"]。

* 重要信息 * ：如果您的系统具有存储磁盘，请在集群提示符处输入本节中的命令。如果您使用的是 V 系列系统或 FlexArray 虚拟化软件并连接到存储阵列，请在维护模式下在此部分中输入命令。

.步骤
. 将 node3 上的 FC 设置与先前从 node1 中捕获的设置进行比较。
. 执行以下操作之一：
+
|===
| 如果要升级的系统 ... | 然后选择… 


| 具有存储磁盘  a| 
在维护模式（启动菜单中的选项 5 ）下，根据需要使用以下命令之一修改 node3 上的 FC 端口：

** 要对目标端口进行编程： `ucadmin modify -m fc -t target <adapter>`
** 要对启动程序端口进行编程： `ucadmin modify -m fc -t initiator <adapter>` ` -t` 是 FC4 类型： target 或 initiator 。




| 是 V 系列系统或具有 FlexArray 虚拟化软件并连接到存储阵列 | 在维护模式（启动菜单中的选项 5 ）下，根据需要使用以下命令修改 node3 上的 FC 端口： `ucadmin modify -m fc -t initiator -f <adapter_port_name>` ` -t` 是 FC4 类型，目标或启动程序。* 注 * ：必须将 FC 端口编程为启动程序。 
|===
. 执行以下操作之一：
+
|===
| 如果要升级的系统 ... | 然后选择… 


| 具有存储磁盘 | 使用以下命令并检查输出，以验证新设置： `ucadmin show` 


| 是 V 系列系统或具有 FlexArray 虚拟化软件并连接到存储阵列 | 使用以下命令并检查输出，以验证新设置： `ucadmin show` 
|===
. 使用以下命令退出维护模式：
+
`halt`

. 使用以下命令从 LOADER 提示符启动系统：
+
`boot_ontap 菜单`

. 输入命令后，请等待，直到系统停留在启动环境提示符处。
. 从维护模式的启动菜单中选择选项 `5` 。
. 执行以下操作之一：
+
|===
| 如果要升级的系统 ... | 然后选择… 


| 具有存储磁盘  a| 
** 如果 node3 具有 UTA/UTA2 卡或 UTA/UTA2 板载端口，请转至部分 link:setting_the_fc_or_uta_uta2_configuration_on_node3.html#check-and-configure-utauta2-ports-on-node3["检查并配置 node3 上的 UTA/UTA2 端口"]。
** 如果 node3 没有 UTA/UTA2 卡或 UTA/UTA2 板载端口，请跳过部分 link:setting_the_fc_or_uta_uta2_configuration_on_node3.html#check-and-configure-utauta2-ports-on-node3["检查并配置 node3 上的 UTA/UTA2 端口"] 然后转到部分 。




| 是 V 系列系统或具有 FlexArray 虚拟化软件并连接到存储阵列  a| 
** 如果 node3 具有 UTA/UTA2 卡或 UTA/UTA2 板载端口，请转至部分 link:setting_the_fc_or_uta_uta2_configuration_on_node3.html#check-and-configure-utauta2-ports-on-node3["检查并配置 node3 上的 UTA/UTA2 端口"]。
** 如果 node3 没有 UTA/UTA2 卡或 UTA/UTA2 板载端口，请跳过部分 link:setting_the_fc_or_uta_uta2_configuration_on_node3.html#check-and-configure-utauta2-ports-on-node3["检查并配置 node3 上的 UTA/UTA2 端口"] 并返回  并恢复步骤 23 中的部分。


|===




== 检查并配置 node3 上的 UTA/UTA2 端口

如果 node3 具有板载 UTA/UTA2 端口或 UTA/UTA2 卡，则必须检查这些端口的配置，并可能对其进行重新配置，具体取决于您希望如何使用升级后的系统。

您必须为 UTA/UTA2 端口配备正确的 SFP+ 模块。

如果要对 FC 使用统一目标适配器（ UTA/UTA2 ）端口，则必须先验证此端口的配置方式。


NOTE: NetApp 营销材料可能会使用术语 UTA2 来指代 CNA 适配器和端口。但是，命令行界面使用术语 CNA 。

您可以使用 `ucadmin show` 命令验证当前端口配置：

....
*> ucadmin show
Adapter Current Mode Current Type Pending Mode Pending Type Admin Status
0e      fc           target       -            initiator    offline
0f      fc           target       -            initiator    offline
0g      fc           target       -            initiator    offline
0h      fc           target       -            initiator    offline
1a      fc           target       -            -            online
1b      fc           target       -            -            online
6 entries were displayed.
....
UTA/UTA2 端口可以配置为原生 FC 模式或 UTA/UTA2 模式。FC 模式支持 FC 启动程序和 FC 目标； UTA/UTA2 模式允许并发 NIC 和 FCoE 流量共享相同的 10 GbE SFP+ 接口并支持 FC 目标。

UTA/UTA2 端口可能位于适配器或控制器上，并且具有以下配置，但您应检查 node3 上的 UTA/UTA2 端口的配置，并根据需要进行更改：

* 订购控制器时订购的 UTA/UTA2 卡会在发货前配置为具有您请求的个性化设置。
* 与控制器分开订购的 UTA/UTA2 卡附带了默认的 FC 目标特性。
* 新控制器上的板载 UTA/UTA2 端口会在发货前配置为具有您请求的个性化设置。
+
* 注意 * ：如果您的系统具有存储磁盘，除非指示您进入维护模式，否则您可以在集群提示符处输入本节中的命令。如果您使用的是 V 系列系统或 FlexArray 虚拟化软件并连接到存储阵列，则可以在维护模式提示符处在此部分中输入命令。要配置 UTA/UTA2 端口，您必须处于维护模式。



.步骤
. 【第 1 步】在 node3 上输入以下命令，以检查端口当前的配置方式：
+
|===
| 如果系统 ... | 然后选择… 


| 具有存储磁盘 | 无需执行任何操作。 


| 是 V 系列系统或具有 FlexArray 虚拟化软件并连接到存储阵列 | `ucadmin show` 
|===
+
系统将显示类似于以下示例的输出：

+
....
*> ucadmin show
Adapter Current Mode Current Type Pending Mode Pending Type Admin Status
0e      fc           initiator    -            -            online
0f      fc           initiator    -            -            online
0g      cna          target       -            -            online
0h      cna          target       -            -            online
0e      fc           initiator    -            -            online
0f      fc           initiator    -            -            online
0g      cna          target       -            -            online
0h      cna          target       -            -            online
*>
....
. 【第 2 步】如果当前 SFP+ 模块与所需用途不匹配，请将其更换为正确的 SFP+ 模块。
+
请联系您的 NetApp 代表以获取正确的 SFP+ 模块。

. `步骤 3]] 查看` ucadmin show 命令的输出，并确定 UTA/UTA2 端口是否具有所需的个性化设置。
. 【第 4 步】执行以下操作之一：
+
|===
| 如果 UTA/UTA2 端口 ... | 然后选择… 


| 没有所需的个性化设置 | 转至 <<step5,第 5 步>>。 


| 拥有所需的个性化特性 | 跳过步骤 5 到步骤 12 ，然后转到 <<step13,第 13 步>>。 
|===
. 【第 5 步】执行以下操作之一：
+
|===
| 如果要配置 | 然后选择… 


| UTA/UTA2 卡上的端口 | 转至 <<step7,第 7 步>> 


| 板载 UTA/UTA2 端口 | 跳过第 7 步，转到 <<step8,第 8 步>>。 
|===
. 【第 6 步】如果适配器处于启动程序模式，并且 UTA/UTA2 端口处于联机状态，请使用以下命令使 UTA/UTA2 端口脱机：
+
`storage disable adapter <adapter_name>`

+
目标模式下的适配器会在维护模式下自动脱机。

. 【第 7 步】如果当前配置与所需用途不匹配，请使用以下命令根据需要更改配置：
+
`ucadmin modify -m fc|cna -t initiators|target <adapter_name>`

+
** ` -m` 是特性模式， `fc` 或 `CNA` 。
** ` -t` 是 FC4 类型， `target` 或 `initiator` 。
+

NOTE: 您必须对磁带驱动器， FlexArray 虚拟化系统和 MetroCluster 配置使用 FC 启动程序。您必须对 SAN 客户端使用 FC 目标。



. 【第 8 步】使用以下命令验证设置：
+
`ucadmin show`

. 【第 9 步】使用以下命令之一验证设置：
+
|===
| 如果系统 ... | 然后选择… 


| 具有存储磁盘 | `ucadmin show` 


| 是 V 系列系统或具有 FlexArray 虚拟化软件并连接到存储阵列 | `ucadmin show` 
|===
+
以下示例中的输出显示， FC4 类型的适配器 1b 正在更改为 `initiator` ，适配器 2a 和 2b 的模式正在更改为 `CNA` ：

+
....
*> ucadmin show
Adapter Current Mode Current Type  Pending Mode Pending Type Admin Status
1a      fc           initiator     -            -            online
1b      fc           target        -            initiator    online
2a      fc           target        cna          -            online
2b      fc           target        cna          -            online
*>
....
. 【第 10 步】输入以下命令之一，使所有目标端口联机，每个端口输入一次：
+
|===
| 如果系统 ... | 然后选择… 


| 具有存储磁盘 | `network fcp adapter modify -node <node_name> -adapter<adapter_name> -state up` 


| 是 V 系列系统或具有 FlexArray 虚拟化软件并连接到存储阵列 | `FCP 配置 <adapter_name> up` 
|===
. 【第 11 步】为端口布线。
. 【第 12 步】执行以下操作之一：
+
|===
| 如果系统 ... | 然后选择… 


| 具有存储磁盘 | 转至 link:verifying_the_node3_installation.html["验证 node3 安装"]。 


| 是 V 系列系统或具有 FlexArray 虚拟化软件并连接到存储阵列 | 恢复时间 link:stage_3_installing_and_booting_node3_overview.html#step23["第 23 步"]。 
|===
. 【第 13 步】使用以下命令退出维护模式：
+
`halt`

. 【第 14 步】运行 `boot_ontap menu` 将节点启动到启动菜单。如果要升级到 A800 ，请转至 <<step23,第 23 步>>。
. 在 node3 上，使用 22/7 转到启动菜单并选择隐藏选项 `boot_after_controller_replacement` 。在提示符处，输入 node1 将 node1 的磁盘重新分配给 node3 ，如下例所示。
+
....
LOADER-A> boot_ontap menu
.
<output truncated>
.
All rights reserved.
*******************************
*                             *
* Press Ctrl-C for Boot Menu. *
*                             *
*******************************
.
<output truncated>
.
Please choose one of the following:
(1)  Normal Boot.
(2)  Boot without /etc/rc.
(3)  Change password.
(4)  Clean configuration and initialize all disks.
(5)  Maintenance mode boot.
(6)  Update flash from backup config.
(7)  Install new software first.
(8)  Reboot node.
(9)  Configure Advanced Drive Partitioning.
(10) Set Onboard Key Manager recovery secrets.
(11) Configure node for external key management.
Selection (1-11)? 22/7
(22/7) Print this secret List
(25/6) Force boot with multiple filesystem disks missing.
(25/7) Boot w/ disk labels forced to clean.
(29/7) Bypass media errors.
(44/4a) Zero disks if needed and create new flexible root volume.
(44/7) Assign all disks, Initialize all disks as SPARE, write DDR labels
.
<output truncated>
.
(wipeconfig)                        Clean all configuration on boot device
(boot_after_controller_replacement) Boot after controller upgrade
(boot_after_mcc_transition)         Boot after MCC transition
(9a)                                Unpartition all disks and remove their ownership information.
(9b)                                Clean configuration and initialize node with partitioned disks.
(9c)                                Clean configuration and initialize node with whole disks.
(9d)                                Reboot the node.
(9e)                                Return to main boot menu.
The boot device has changed. System configuration information could be lost. Use option (6) to restore the system configuration, or option (4) to initialize all disks and setup a new system.
Normal Boot is prohibited.
Please choose one of the following:
(1)  Normal Boot.
(2)  Boot without /etc/rc.
(3)  Change password.
(4)  Clean configuration and initialize all disks.
(5)  Maintenance mode boot.
(6)  Update flash from backup config.
(7)  Install new software first.
(8)  Reboot node.
(9)  Configure Advanced Drive Partitioning.
(10) Set Onboard Key Manager recovery secrets.
(11) Configure node for external key management.
Selection (1-11)? boot_after_controller_replacement
This will replace all flash-based configuration with the last backup to disks. Are you sure you want to continue?: yes
.
<output truncated>
.
Controller Replacement: Provide name of the node you would like to replace:<nodename of the node being replaced>
Changing sysid of node node1 disks.
Fetched sanown old_owner_sysid = 536940063 and calculated old sys id = 536940063
Partner sysid = 4294967295, owner sysid = 536940063
.
<output truncated>
.
varfs_backup_restore: restore using /mroot/etc/varfs.tgz
varfs_backup_restore: attempting to restore /var/kmip to the boot device
varfs_backup_restore: failed to restore /var/kmip to the boot device
varfs_backup_restore: attempting to restore env file to the boot device
varfs_backup_restore: successfully restored env file to the boot device wrote key file "/tmp/rndc.key"
varfs_backup_restore: timeout waiting for login
varfs_backup_restore: Rebooting to load the new varfs
Terminated
<node reboots>
System rebooting...
.
Restoring env file from boot media...
copy_env_file:scenario = head upgrade
Successfully restored env file from boot media...
Rebooting to load the restored env file...
.
System rebooting...
.
<output truncated>
.
WARNING: System ID mismatch. This usually occurs when replacing a boot device or NVRAM cards!
Override system ID? {y|n} y
.
Login:
....
+

NOTE: 在上述控制台输出示例中，如果系统使用高级磁盘分区（ ADP ）磁盘， ONTAP 将提示您输入配对节点名称。

. 【第 16 步】如果系统进入重新启动循环并显示消息 `未找到磁盘` ，则表示系统已将 FC 或 UTA/UTA2 端口重置回目标模式，因此无法查看任何磁盘。要解决此问题，请继续 <<step17,第 17 步>> to <<step22,第 22 步>>或转到第节 link:verifying_the_node3_installation.html["验证 node3 安装"]。
. 在自动启动期间按 Ctrl-C 可在 `LOADER>` 提示符处停止节点。
. 在 LOADER 提示符处，使用以下命令进入维护模式：
+
`boot_ontap maint`

. 在维护模式下，使用以下命令显示先前设置的所有启动程序端口，这些端口现在均处于目标模式：
+
`ucadmin show`

+
使用以下命令将端口重新更改为启动程序模式：

+
`ucadmin modify -m fc -t initiator -f < 适配器名称 >`

. 【第 20 步】使用以下命令验证端口是否已更改为启动程序模式：
+
`ucadmin show`

. 【第 21 步】使用以下命令退出维护模式：
+
`halt`

. 在 LOADER 提示符处，使用以下命令启动：
+
`boot_ontap`

+
现在，在启动时，节点可以检测到先前分配给它的所有磁盘，并可按预期启动。

. 【第 23 步】如果要从具有外部磁盘的系统升级到支持内部和外部磁盘的系统（例如， AFF A800 系统），请将 node1 聚合设置为根聚合，以确保 node3 从 node1 的根聚合启动。要设置根聚合，请转到启动菜单并选择选项 `5` 以进入维护模式。
+

CAUTION: 您必须按所示的确切顺序执行以下子步骤；否则可能发生原因会导致中断甚至数据丢失。

+
以下操作步骤会将 node3 设置为从 node1 的根聚合启动：

+
.. 使用以下命令进入维护模式：
+
`boot_ontap maint`

.. 使用以下命令检查 node1 聚合的 RAID ，丛和校验和信息：
+
`aggr status -r`

.. 使用以下命令检查 node1 聚合的状态：
+
`聚合状态`

.. 如有必要，使用以下命令使 node1 聚合联机：
+
`aggr_online root_aggr_from_<node1>`

.. 使用以下命令防止 node3 从其原始根聚合启动：
+
`aggr offline <root_aggr_on_node3>`

.. 使用以下命令将 node1 根聚合设置为 node3 的新根聚合：
+
`aggr options aggr_from_<node1> root`

.. 使用以下命令验证 node3 的根聚合是否已脱机，从 node1 接管的磁盘的根聚合是否已联机并设置为 root ：
+
`聚合状态`

+

NOTE: 如果不执行上一个子步骤，发生原因 node3 可能会从内部根聚合启动，或者它可能会发生原因系统以假定存在新的集群配置或提示您确定一个集群配置。

+
下面显示了命令输出的示例：

+
....
Aggr            State   Status    Options
aggr 0_nst_fas  8080_15 online    raid_dp, aggr root,  nosnap=on
                                  fast zeroed, 64-bit
aggr            0       offline   raid_dp, aggr, diskroot
                                  fast zeroed, 64-bit
....



